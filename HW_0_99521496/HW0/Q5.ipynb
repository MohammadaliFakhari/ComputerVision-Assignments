{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23386,"status":"ok","timestamp":1677527235506,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"},"user_tz":-210},"id":"_oWh7cFPg5vE","outputId":"5d5bac18-5abe-4736-ae4f-3b962aa74940"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"lNKYy5P_DEV-"},"source":["## Modifying the picture with opencv and numpy libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yexCZ1RCByIY"},"outputs":[],"source":["import numpy as np\n","import copy\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_GJ8Q3Pgy2r"},"outputs":[],"source":["!wget -q https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7.weights "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLBUStaogy2s"},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov7.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Z72Jw09-zmZ"},"outputs":[],"source":["net = cv2.dnn.readNetFromDarknet('yolov7.cfg', 'yolov7.weights')\n","net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RCASdxi--fw"},"outputs":[],"source":["yolo_model = cv2.dnn_DetectionModel(net)\n","yolo_model.setInputParams(size=(1280, 1280), scale=1 / 255, swapRB=True)"]},{"cell_type":"markdown","metadata":{"id":"xThGxCMDDUFO"},"source":["**Just run the above cells without any changes**"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"CBTcXsRpKjRM","executionInfo":{"status":"ok","timestamp":1677538832212,"user_tz":-210,"elapsed":489,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}},"outputId":"245e2881-0967-41ef-ed63-de4f99e03696","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["heights: 721 pixels, width: 1281 pixels\n","type of value: uint8\n","average the complete image: 139.98719468688319\n","average the image over 3 channel: [139.17862475 144.50184225 136.28111706]\n","The minimum of red channel: 10, The maximum of red channel: 255\n","The minimum of green channel: 10, The maximum of green channel: 255\n","The minimum of blue channel: 0, The maximum of blue channel: 255\n","The smallest pixel: 0, The largest pixel: 255\n"]}],"source":["\"\"\"\n","Please read the provided image in RGB with opencv lib and print the matrices\n","\n","see bellow links:\n","https://numpy.org/doc/stable/reference/generated/numpy.maximum.html\n","https://numpy.org/doc/stable/reference/generated/numpy.minimum.html\n","https://numpy.org/doc/stable/reference/generated/numpy.mean.html\n","\"\"\"\n","path = '/content/drive/MyDrive/ColabNotebooks/FCV/HW0/Q5.png'\n","# read image with cv2 in 'BGR' mode\n","image = cv2.imread(path)\n","# conv the 'BGR' image to 'RGB'\n","rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","print(f'heights: {rgb_img.shape[0]} pixels, width: {rgb_img.shape[1]} pixels')\n","print(f'type of value: {rgb_img.dtype}')\n","print(f'average the complete image: {np.average(rgb_img)}\\naverage the image over 3 channel: {np.average(rgb_img, axis=(0,1))}')\n","# red channel\n","print(f'The minimum of red channel: {rgb_img[:,:,0].min()}, The maximum of red channel: {rgb_img[:,:,0].max()}')\n","# green channel\n","print(f'The minimum of green channel: {rgb_img[:,:,1].min()}, The maximum of green channel: {rgb_img[:,:,1].max()}')\n","# blue channel\n","print(f'The minimum of blue channel: {rgb_img[:,:,2].min()}, The maximum of blue channel: {rgb_img[:,:,2].max()}')\n","\n","# find min and mux in image\n","print(f'The smallest pixel: {rgb_img.min(axis=(0,1,2))}, The largest pixel: {rgb_img.max(axis=(0,1,2))}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N3xB0Rh2FRZ_"},"outputs":[],"source":["\n","#### Just run this cell \n","\n","\n","CONFIDENCE_THRESHOLD = 0.2\n","NMS_THRESHOLD = 0.4 \n","\n","classes, scores, boxes = yolo_model.detect(image, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n","\n","detections = [(box, score) for classid, score, box in zip(classes, scores, boxes)]"]},{"cell_type":"markdown","metadata":{"id":"Ot4ivZb6H7r7"},"source":["the result of the detection is classes of each object, \n","confidence of predicting the class of that object and parameters of the bounding box\n","\n","for every bounding box, we have bellow information:\n","\n","x_min: the x coordinate of the left up corner of the bounding box\n","\n","y_min: the y coordinate of the left up corner of the bounding box\n","\n","w: the width of the bounding box\n","\n","h: the height of the bounding box"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjB_FADQH7bF"},"outputs":[],"source":["### please print the details of the detections\n","for i in range(len(detections)):\n","  print(f'Confidence of predict: {detections[i][1]}, x_min: {detections[i][0][0]}, y_min: {detections[i][0][1]}, \\\n","  width: {detections[i][0][2]}, height: {detections[i][0][3]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OplX-80cLma3"},"outputs":[],"source":["def visualize(frame, detections):\n","  \"\"\"\n","  Draw all bounding boxes on the main original image and show the result\n","  Then save result with result.png name\n","\n","  see the bellow links:\n","  https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\n","  https://www.geeksforgeeks.org/python-opencv-cv2-imwrite-method/\n","  \"\"\"\n","\n","  ########################################\n","  ########### YOUR CODES GO HERE #########\n","  generated_img = copy.deepcopy(rgb_img)\n","  for i in range(len(detections)):\n","    cv2.rectangle(generated_img, (detections[i][0][0], detections[i][0][1]), \\\n","                  (detections[i][0][0]+detections[i][0][2], detections[i][0][1]+detections[i][0][3]), color=(255,0,0))\n","\n","  path = '/content/drive/MyDrive/ColabNotebooks/FCV/HW0/result.png' \n","  bgr_generated_img = cv2.cvtColor(generated_img, cv2.COLOR_RGB2BGR)\n","  cv2.imwrite(path, bgr_generated_img)\n","  plt.imshow(generated_img)\n","\n","  ########################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPc3unKsLwaj"},"outputs":[],"source":["visualize(image, detections)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWQOx8degy28"},"outputs":[],"source":["# Check if file has been saved or not\n","!ls drive/MyDrive/ColabNotebooks/FCV/HW0/result.png && echo yes || echo no"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ann_fuzzy","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"ae9f58b7d9e04f28b9243080ecc95e12abe73d3533e4e38f6cc83b7244ec2903"}}},"nbformat":4,"nbformat_minor":0}